# Zephery-weiboanalysis基于Adaboosting的情感分析研究

* [Github地址](https://github.com/Zephery/weiboanalysis)

个人总结，项目主要分为以下三部分

## 基于SVM的广告微博和正常微博分类

* 代码  https://github.com/Zephery/weiboanalysis/blob/master/svm_train.py

* 结合文档总结流程如下
    * 数据获取：读取已知advertise和normal微博文档；
    
    * 构建标准特征： 根据以上文档，计算得到特征词：pynlpir_feature()函数在分词后通过计算每个词的卡方统计量，根据卡方统计量从高到低选择n个词作为标准调整；
    
    * 准备训练和测试数据： 对每条微博文档进行分词，将分词结果与上一步的标准特征比对，构建特征向量形如[{'试试': 'True', '正': 'True', '礼': 'True', '人品': 'True', '专': 'True', '力': 'True', '事': 'True', '玩耍': 'True', '说': 'True', '博': 'True', '微': 'True', '[酷]': 'True', '享': 'True', '奖品': 'True', '领取': 'True', '太': 'True', '等级': 'True', '愉快': 'True'}, 'adv'],其本质是微博分词后的每个词对应在标准特征中是否存在的键值对；

    * 进行模型训练


## 基于贝叶斯的情感分析

* 代码 https://github.com/Zephery/weiboanalysis/blob/master/Bayes.py

* 结合文档总结流程如下
    * 数据读取：读取已知情感分类的微博文档；

    * 构建标准特征: build_key_word()函数通过词频构建标准特征词；

    * 准备训练和测试数据，对每条微博向量化：对每条微博进行分词，并将分词结果与标准特征词对应构建特征向量；假如上述中的特征提取中构建出来的单词特征为[‘喜欢’,’失望’,’快乐’,’越来越好’,’晚安’]，长度为m，矢量化的时候如果一条微博为：生日快乐，晚安。那么，构建出来的矩阵为：[0,0,1,0,1]

    * 进行模型训练等

## 基于Adaboosting



## 总结

* 标准特征构建：对已知类别的文档进行分词，然后根据词频/卡方统计量等选择TOP N作为标注特征;

* 文本编码: 将文本分词后，与标准特征词对应，进行编码(根据词是否在文档中存在；每个词在文档的tfidf值等编码)；完成编码后进行训练